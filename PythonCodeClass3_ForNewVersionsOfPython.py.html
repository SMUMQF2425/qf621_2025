<!DOCTYPE html>
<html><head><link rel="stylesheet" href="https://templates.lcs.brightspace.com/lib/assets/css/styles.min.css"></head><body style="color: rgb(32, 33, 34); font-family: undefined;"><div>
<pre>#GENERAL INSTRUCTIONS:<br>#1.  LINES 4 to 150 ARE OLD SCRIPT FROM CLASS 1<br><br><br>import pandas as pd;<br>import numpy as np;<br><br><br>#Utility method takes in daily % pnl vector and computes portfolio diagnostics<br>#daily % pnl is inputed as a dataframe, with date as index and corresponding pnl for that date as the value<br>def portfolioDiagnostics(signal_df, label):<br>    #NET SECTOR EXPOSURES<br>    import matplotlib.pyplot as plt<br>    plt.figure();<br>    sector_df = pd.read_csv("sector.csv", on_bad_lines='skip')<br>    d = sector_df.set_index('ticker').to_dict()<br>    signal_df2 = signal_df.copy(deep=True)<br>    signal_df2.columns = signal_df2.columns.to_series().map(d['sector'])<br>    uniquesector = list(set(signal_df2.columns))<br>    for tsector in uniquesector:<br>        if (str(tsector)=='nan'):<br>            continue;<br>        tmean = signal_df2.loc[:, tsector].sum(axis=1)<br>        tmean[~np.isfinite(tmean)] = 0<br>        plt.plot(tmean.values, label=tsector)<br>        plt.legend();<br>        plt.title(label+" NET EXPOSURE")<br>        plt.show(block=False)<br>    return<br><br><br>#Utility method takes in daily % pnl vector and computes pnl diagnostics<br>#daily % pnl is inputed as a dataframe, with date as index and corresponding pnl for that date as the value<br>def pnlPerformance(pnl, label):<br>    cumpnl = pnl.cumsum(skipna = True)<br>    import matplotlib.pyplot as plt<br>    import numpy as np<br>    sharpe = pnl.mean()/np.std(pnl)<br>    sharpe = sharpe*np.sqrt(252)<br>    print("")<br>    print ("PERFORMANCE STATISTICS FOR "+label);<br>    print("Daily annualized sharpe: "+str(sharpe))<br>    print ("Average annual returns: "+str(pnl.mean()*252*100)+"%")<br>    print ("Total returns: "+str(pnl.sum()*100)+"%");<br>    highwatermark_df = cumpnl.cummax();<br>    drawdown_df = cumpnl - highwatermark_df;<br>    maxdrawdown = drawdown_df.min();<br>    print ("Max drawdown: "+str(maxdrawdown*100)+"%");<br>    plt.plot(cumpnl.values, label = label);<br>    plt.legend();<br>    plt.show(block=False);<br>    plt.title("Cumulative PNL chart")<br>    #HERE, we compute performance during 'stressed' historical periods<br>    stressedmarkets = dict()<br>    stressedmarkets["Covid19"] = (20200301, 20200317);          #Market crash 1H March 2020<br>    stressedmarkets["Dec18"] = (20181215, 20181231);            #Market crash last 2 weeks<br>    stressedmarkets["Fall2015"] = (20150701, 20150901);         #Taper tantrum / EU debt crisis.  24 Aug 2015 was "BlackMonday" for Asian, EU and US markets<br>    stressedmarkets["Oct14"] = (20141001, 20141031);            #Treasury flash crash on 15 Oct 2014<br>    stressedmarkets["Aug2013"] = (20130820, 20130825);          #Flash freeze on 22 Aug 2013<br><br>    for tkey in stressedmarkets.keys():<br>        mask = pnl.index.to_series().between(stressedmarkets[tkey][0], stressedmarkets[tkey][1])<br>        print("Stressed period return during "+tkey+":  "+str(pnl[mask].sum()*100)+"%")<br>    print("===========================")<br>    print("")<br><br><br>#=======ACTUAL STRATEGY SCRIPT STARTS HERE============================#<br><br>russell_df = pd.read_csv("russell2000pvdata.csv", on_bad_lines='skip')<br>vars = ['open', 'high', 'low', 'close', 'volume']<br>rawdata = {}<br>reversiontimehorizon = 10           #NUMBER OF TRADING DAYS TO COMPUTE MEAN REVERSION OVER.  THIS IS A PARAMETER FOR FITTING<br>universesize = 2000                 #SIZE OF PORTFOLIO IN NUMBER OF STOCKS.  IF THIS IS MORE THAN 2000, IT WILL GENERALLY JUST BE CAPPED AT 2000 SINCE BASE UNIVERSE IS RUSSELL 2000<br>maxindividualweight = 0.01          #MAXIMUM FRACTION A SINGLE POSITION CAN TAKE UP OF ENTIRE PORTFOLIO.  0.01 MEANS 1%.  i.e. if you have a portfolio of $100 million, max single position size is $1 million<br><br>#MARKET NEUTRAL STRATEGY BASED ON N DAY REVERSION, BASE UNIVERSE IS STOCKS IN RUSSELL 2000<br>for tvar in vars:<br>    rawdata[tvar] = russell_df.loc[:, ['tickerid', 'ticker', 'date', tvar]]<br>    rawdata[tvar] = rawdata[tvar].pivot(index = 'date', columns = 'ticker', values = tvar)<br>    rawdata[tvar] = rawdata[tvar].iloc[:, :universesize]<br><br>return_df = (rawdata['close'] / rawdata['close'].shift(1)) - 1<br>signal_df = -return_df.rolling(reversiontimehorizon, min_periods = 3).mean()<br>signal_df = signal_df.subtract(signal_df.mean(axis=1), axis='index')<br>signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')<br>signal_df = signal_df.shift(1)                                              #TO AVOID FORWARD BIAS.  WE USE YESTERDAY'S INFORMATION TO EXECUTE AT TODAY'S CLOSE PRICES<br>for i in range(3):<br>    signal_df[signal_df &gt; maxindividualweight] = maxindividualweight<br>    signal_df[signal_df &lt; -maxindividualweight] = -maxindividualweight<br>    signal_df = signal_df.subtract(signal_df.mean(axis=1), axis='index')<br>    signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')<br>pnl_df = signal_df * return_df.shift(-1)                                    #BASED ON YESTERDAY'S INFORMATION, WE EXECUTE AT TODAY'S CLOSE PRICES AND COMPUTE OUR PNL BASED ON TOMORROW'S RETURN<br>pnl = pnl_df.sum(axis=1)<br>pnlPerformance(pnl, "MARKET NEUTRAL")<br>marketneutralportfolio = signal_df.copy(deep=True)<br><br><br>#SECTOR NEUTRAL STRATEGY BASED ON N DAY REVERSION, ALL STOCKS IN RUSSELL 2000<br>sector_df = pd.read_csv("sector.csv", on_bad_lines='skip')<br>d = sector_df.set_index('ticker').to_dict()<br>signal_df2 = signal_df.copy(deep=True)                                      #WE JUST REUSE THE PORTFOLIO WEIGHTS FROM PREVIOUS STRATEGY, SINCE WE ARE JUST NEUTRALIZING DIFFERENTLY HERE<br>signal_df2.columns = signal_df2.columns.to_series().map(d['sector'])<br>uniquesector = list(set(signal_df2.columns))<br>for tsector in uniquesector:<br>    if (str(tsector)=='nan'):<br>        continue;<br>    tmean = signal_df2.loc[:, tsector].mean(axis=1)<br>    tmean[~np.isfinite(tmean)] = 0<br>    signal_df2.loc[:, tsector] = signal_df2.loc[:, tsector].subtract(tmean, axis='index');<br>signal_df = pd.DataFrame(data = signal_df2.values, index = signal_df.index, columns = signal_df.columns)<br>signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')<br>for i in range(3):<br>    signal_df[signal_df &gt; maxindividualweight] = maxindividualweight<br>    signal_df[signal_df &lt; -maxindividualweight] = -maxindividualweight<br>    signal_df = signal_df.subtract(signal_df.mean(axis=1), axis='index')<br>    signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')<br>pnl_df = signal_df * return_df.shift(-1)<br>pnl = pnl_df.sum(axis=1)<br>reversionsectorneutral = pnl.copy(deep=True)<br>pnlPerformance(pnl, "SECTOR NEUTRAL")<br>sectorneutralportfolio = signal_df.copy(deep=True)<br><br><br>#NON MARKET NEUTRAL STRATEGY BASED ON N DAY REVERSION, BASE UNIVERSE IS STOCKS IN RUSSELL 2000<br>for tvar in vars:<br>    rawdata[tvar] = russell_df.loc[:, ['tickerid', 'ticker', 'date', tvar]]<br>    rawdata[tvar] = rawdata[tvar].pivot(index = 'date', columns = 'ticker', values = tvar)<br>    rawdata[tvar] = rawdata[tvar].iloc[:, :universesize]<br><br>return_df = (rawdata['close'] / rawdata['close'].shift(1)) - 1<br>signal_df = -return_df.rolling(reversiontimehorizon, min_periods = 3).mean()<br>signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')<br>signal_df = signal_df.shift(1)<br><br>for i in range(3):<br>    signal_df[signal_df &gt; maxindividualweight] = maxindividualweight<br>    signal_df[signal_df &lt; -maxindividualweight] = -maxindividualweight<br>    signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')<br>pnl_df = signal_df * return_df.shift(-1)<br>pnl = pnl_df.sum(axis=1)<br>pnlPerformance(pnl, "NON MARKET NEUTRAL")<br>nonmarketneutralportfolio = signal_df.copy(deep=True)<br><br>portfolioDiagnostics(marketneutralportfolio, "MARKET NEUTRAL");<br>portfolioDiagnostics(sectorneutralportfolio, "SECTOR NEUTRAL");<br>portfolioDiagnostics(nonmarketneutralportfolio, "NON MARKET NEUTRAL");<br><br><br>#PTG SCRIPT.  YOU NEED TO UNZIP ADDITIONAL CSV FILE FROM "PRICETARGETS.ZIP" INTO SAME DIRECTORY<br>russell1000_df = pd.read_csv("russell1000pvdata.csv", on_bad_lines='skip')<br>vars = ['open', 'high', 'low', 'close', 'volume']<br>rawdata_r1000 = {}<br>universesize = 1000                 #SIZE OF PORTFOLIO IN NUMBER OF STOCKS.  IF THIS IS MORE THAN 2000, IT WILL GENERALLY JUST BE CAPPED AT 2000 SINCE BASE UNIVERSE IS RUSSELL 2000<br>maxindividualweight = 0.01          #MAXIMUM FRACTION A SINGLE POSITION CAN TAKE UP OF ENTIRE PORTFOLIO.  0.01 MEANS 1%.  i.e. if you have a portfolio of $100 million, max single position size is $1 million<br><br>#MARKET NEUTRAL STRATEGY BASED ON N DAY REVERSION, BASE UNIVERSE IS STOCKS IN RUSSELL 2000<br>for tvar in vars:<br>    rawdata_r1000[tvar] = russell1000_df.loc[:, ['tickerid', 'ticker', 'date', tvar]]<br>    rawdata_r1000[tvar] = rawdata_r1000[tvar].pivot(index = 'date', columns = 'ticker', values = tvar)<br>    rawdata_r1000[tvar] = rawdata_r1000[tvar].iloc[:, :universesize]<br><br>return_r1000_df = (rawdata_r1000['close'] / rawdata_r1000['close'].shift(1)) - 1<br><br>ptg = pd.read_csv("russell1000ptg.csv", on_bad_lines='skip')<br>ptgvars = ptg.columns[3:]<br>rawdataptg = {}<br>for tvar in ptgvars:<br>    rawdataptg[tvar] = ptg.loc[:, ['tickerid', 'ticker', 'date', tvar]]<br>    rawdataptg[tvar] = rawdataptg[tvar].pivot(index = 'date', columns = 'ticker', values = tvar)<br>    rawdataptg[tvar] = rawdataptg[tvar].iloc[:, :universesize]<br><br>ptgforecast = rawdataptg['PTGmean']/(rawdata_r1000['close'])<br>ptgforecast = 2*ptgforecast - ptgforecast.shift(10)                                                                        #THIS IS EQUIVALENT TO SORTING ON E(PRICE APPRECIATION) + DELTA(E(PRICE APPRECIATION), BOTH OF WHICH ARE MOMENTUM SIGNALS<br>ptgforecast = ptgforecast.fillna(method='ffill', limit = 66)<br>signal_df = ptgforecast.subtract(ptgforecast.mean(axis=1), axis='index')<br>signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')<br>signal_df = signal_df.shift(1)<br>for i in range(3):<br>    signal_df[signal_df &gt; maxindividualweight] = maxindividualweight<br>    signal_df[signal_df &lt; -maxindividualweight] = -maxindividualweight<br>    signal_df = signal_df.subtract(signal_df.mean(axis=1), axis='index')<br>    signal_df = signal_df.divide(signal_df.abs().sum(axis=1), axis='index')<br>pnl_df = signal_df * return_r1000_df.shift(-1)<br>pnl = pnl_df.sum(axis=1)<br>ptgmarketneutralpnl = pnl.copy(deep=True)<br>pnlPerformance(pnl, "PTG MARKET NEUTRAL")<br><br>#HERE, WE INCORPORATE TRANSACTIONS COSTS IN OUR SAME STRATEGY FROM ABOVE<br>bpspertrade = 5<br>pertradecost = bpspertrade/10000                                                                                            #ASSUME 5 BPS PER TRADE = bid-ask spread + commissions + exchange fees + market impact.  FOR RUSSELL 1000, THIS FIGURE IS PROBABLY "MOSTLY" CORRECT ON AVERAGE AS OF MID 2021 ASSUMING (BULGE BRACKET PRIME BROKER OR AT LEAST INTERACTIVE BROKERS) AND MODEST AUM (SAY USD100M)<br>turnover_df = (signal_df - signal_df.shift(1).fillna(0)).abs().fillna(0)<br>totaltradecosts = turnover_df*pertradecost<br>dailytradecosts = totaltradecosts.sum(axis=1)<br>pnl_aftercost = pnl - dailytradecosts<br>print ("AVERAGE DAILY TURNOVER NO DECAY: "+str(turnover_df.sum(axis=1).mean()))                                             #HOW MUCH WE ACTIVELY TRADE EACH STOCK EVERYDAY, AS % OF PORTFOLIO GMV<br>pnlPerformance(pnl, "PTG MARKET NEUTRAL NO TRADING COSTS")<br>pnlPerformance(pnl_aftercost, "PTG MARKET NEUTRAL AFTER TRADING COSTS")<br><br>#OPTIMIZING AFTER COST PERFORMANCE<br>decay = 2<br>signal_df_decay = signal_df.rolling(decay).mean();                                                                          #SPREAD OUR TRADES EVENLY OVER N DAYS.   FOR ILLUSTRATIVE PURPOSES ONLY.  IN PRACTICE, YOU MAY WISH TO ASSIGN A HEAVIER WEIGHT TO MORE RECENT TARGET PORTFOLIO RATHER THAN JUST SPREAD EVENLY<br>turnover_df_decay = (signal_df_decay - signal_df_decay.shift(1).fillna(0)).abs().fillna(0)<br>totaltradecosts_decay = turnover_df_decay * pertradecost<br>dailytradecosts_decay = totaltradecosts_decay.sum(axis=1)<br>pnl_beforecost_decay = (signal_df_decay * return_r1000_df.shift(-1)).sum(axis=1)<br>pnl_aftercost_decay = pnl_beforecost_decay - dailytradecosts_decay<br>print ("AVERAGE DAILY TURNOVER DECAY"+str(decay)+": "+str(turnover_df_decay.sum(axis=1).mean()))                            #HOW MUCH WE ACTIVELY TRADE EACH STOCK EVERYDAY, AS % OF PORTFOLIO GMV<br>pnlPerformance(pnl_beforecost_decay, "PTG MARKET NEUTRAL NO TRADING COSTS DECAY"+str(decay))<br>pnlPerformance(pnl_aftercost_decay, "PTG MARKET NEUTRAL AFTER TRADING COSTS DECAY"+str(decay))<br><br></pre>
</div></body></html>